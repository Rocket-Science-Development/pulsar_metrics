{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, validator\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from collections.abc import Iterable\n",
    "from functools import partial\n",
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv('kidney_test.csv')\n",
    "\n",
    "df_ref['model_id'] = '1'\n",
    "df_ref['model_version'] = '1'\n",
    "df_ref['pred_timestamp'] = datetime(2022,7,1)\n",
    "df_ref['period'] = 'reference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('dataframe_client.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>al</th>\n",
       "      <th>ane</th>\n",
       "      <th>appet</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bp</th>\n",
       "      <th>bu</th>\n",
       "      <th>cad</th>\n",
       "      <th>...</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>sc</th>\n",
       "      <th>sg</th>\n",
       "      <th>sod</th>\n",
       "      <th>su</th>\n",
       "      <th>target</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>y_name</th>\n",
       "      <th>pred_timestamp</th>\n",
       "      <th>eval_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-06T00:35:06.565042Z</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.020</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-09T11:47:43.406341Z</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.025</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-12T12:24:23.593044Z</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.025</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-12T12:36:14.661246Z</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.025</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-16T11:34:56.583918Z</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.025</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>2022-08-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time   age   al  ane  appet  ba    bgr    bp    bu  \\\n",
       "0  2022-08-06T00:35:06.565042Z  83.0  3.0    1      1   0  102.0  70.0  60.0   \n",
       "1  2022-08-09T11:47:43.406341Z  25.0  0.0    0      0   0  121.0  80.0  19.0   \n",
       "2  2022-08-12T12:24:23.593044Z  25.0  0.0    0      0   0  121.0  80.0  19.0   \n",
       "3  2022-08-12T12:36:14.661246Z  25.0  0.0    0      0   0  121.0  80.0  19.0   \n",
       "4  2022-08-16T11:34:56.583918Z  25.0  0.0    0      0   0  121.0  80.0  19.0   \n",
       "\n",
       "   cad  ... rbcc   sc     sg    sod  su  target     wbcc  y_name  \\\n",
       "0    0  ...  3.1  2.6  1.020  115.0   0       1  12800.0     NaN   \n",
       "1    0  ...  5.3  1.2  1.025  142.0   0       0   6900.0     NaN   \n",
       "2    0  ...  5.3  1.2  1.025  142.0   0       0   6900.0     NaN   \n",
       "3    0  ...  5.3  1.2  1.025  142.0   0       0   6900.0     NaN   \n",
       "4    0  ...  5.3  1.2  1.025  142.0   0       0   6900.0     ABC   \n",
       "\n",
       "  pred_timestamp  eval_timestamp  \n",
       "0     2022-08-21      2022-08-26  \n",
       "1     2022-08-21      2022-08-26  \n",
       "2     2022-08-21      2022-08-26  \n",
       "3     2022-08-21      2022-08-26  \n",
       "4     2022-08-21      2022-08-26  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulsar_metrics.metrics.base import MetricResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = MetricResults(name = \"accuracy\", type = \"performance\", model_id = \"1\", model_version = \"1.0\", period_end = datetime(2022,8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricResults(metric_name=None, type='performance', model_id='1', model_version='1.0', data_id=None, feature=None, value=None, status=None, threshold=None, period_start=None, period_end=datetime.datetime(2022, 8, 10, 0, 0), eval_timestamp=datetime.datetime(2022, 9, 7, 14, 5, 1, 918027), conf_int=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulsar_metrics.metrics.performance import PerformanceMetric\n",
    "\n",
    "precision = PerformanceMetric(name = 'auc', data = df_ref, y_name = 'clf_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricResults(metric_name='auc', type='performance', model_id='1', model_version='1', data_id=None, feature='prediction', value=0.7727272727272727, status=False, threshold=0.5, period_start=Timestamp('2022-07-01 00:00:00'), period_end=Timestamp('2022-07-01 00:00:00'), eval_timestamp=datetime.datetime(2022, 9, 7, 14, 5, 1, 918027), conf_int=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision._result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_result = precision.evaluate(bootstrap=False,  threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_id'\n"
     ]
    }
   ],
   "source": [
    "from pulsar_metrics.analyzers.base import Analyzer\n",
    "analysis = Analyzer(name = 'First Analyzer', description='My first Analyzer', data = df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "precision = PerformanceMetric(name = 'accuracy', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "precision = PerformanceMetric(name = 'recall', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, average = 'micro', threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1\n",
    "precision = PerformanceMetric(name = 'f1', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, average = 'micro', threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true contains only one label (0). Please provide the true labels explicitly through the labels argument.\n"
     ]
    }
   ],
   "source": [
    "# log_loss\n",
    "# this metric is not working with kidney disease test data\n",
    "precision = PerformanceMetric(name = 'log_loss', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, threshold = 0.5)\n",
    "\n",
    "\n",
    "# dict = vars(precision_result)\n",
    "# df_compute = pd.DataFrame([dict])\n",
    "# df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    }
   ],
   "source": [
    "#auc\n",
    "# this metric is not working with kidney disease test data\n",
    "precision = PerformanceMetric(name = 'auc', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, threshold = 0.5)\n",
    "\n",
    "\n",
    "# dict = vars(precision_result)\n",
    "# df_compute = pd.DataFrame([dict])\n",
    "# df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/manuarya/Projects/pulsar-metrics/pulsar-metrics/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:879: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#aucpr\n",
    "# this metric is not working with kidney disease test data\n",
    "precision = PerformanceMetric(name = 'aucpr', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True, threshold = 0.5)\n",
    "\n",
    "\n",
    "# dict = vars(precision_result)\n",
    "# df_compute = pd.DataFrame([dict])\n",
    "# df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brier\n",
    "precision = PerformanceMetric(name = 'brier', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True,  threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse\n",
    "precision = PerformanceMetric(name = 'mse', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True,  threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mae\n",
    "precision = PerformanceMetric(name = 'mae', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True,  threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mape\n",
    "precision = PerformanceMetric(name = 'mape', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True,  threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2\n",
    "precision = PerformanceMetric(name = 'r2', data = df_ref, y_name = 'clf_target')\n",
    "precision._result\n",
    "precision_result = precision.evaluate(bootstrap=True,  threshold = 0.5)\n",
    "\n",
    "\n",
    "dict = vars(precision_result)\n",
    "df_compute = pd.DataFrame([dict])\n",
    "df_result = pd.concat([df_result, df_compute], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulsar_metrics.metrics.drift import DriftTestMetric, DriftMetric, DriftMetricsFuncs, DriftTestMetricsFuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kl', 'wasserstein']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DriftMetricsFuncs._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ttest', 'manwu', 'levene', 'bftest', 'ks_2samp', 'CvM', 'chi2']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DriftTestMetricsFuncs._member_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022-08-21'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.pred_timestamp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['pred_timestamp'] = pd.to_datetime(df_new.pred_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'bgr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driftTest = DriftTestMetric(name = 'ks_2samp', data = df_new, feature_name = feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-08-21'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driftTest._period_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.4166666666666667, pvalue=0.2557751845677543)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DriftTestMetricsFuncs['ks_2samp'].value(driftTest._column, df_ref[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifttest_result = driftTest.evaluate(alpha = 0.05, reference = df_ref[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricResults(metric_name='ks_2samp', type='drift', model_id='1', model_version='nan', data_id=None, feature='bgr', value=0.2557751845677543, status=False, threshold=0.05, period_start=Timestamp('2022-08-21 00:00:00'), period_end=Timestamp('2022-08-21 00:00:00'), eval_timestamp=datetime.datetime(2022, 9, 7, 14, 32, 2, 191586), conf_int=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifttest_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'period_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m MetricResults(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 metric_name\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdrift\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 model_id\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_model_id,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 model_version\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_model_version,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 feature\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_feature_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                 value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                 conf_int\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                 status\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                 threshold\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                 period_start\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_period_start,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 period_end\u001b[39m=\u001b[39;49mdriftTest\u001b[39m.\u001b[39;49m_period_end,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adelbenlagra/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/metric_compute_adel.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             )\n",
      "File \u001b[0;32m~/anaconda3/envs/rs-metrics2/lib/python3.9/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs-metrics2/lib/python3.9/site-packages/pydantic/main.py:1038\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs-metrics2/lib/python3.9/site-packages/pydantic/fields.py:871\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.validate\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs-metrics2/lib/python3.9/site-packages/pydantic/fields.py:1121\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField._apply_validators\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/rs-metrics2/lib/python3.9/site-packages/pydantic/class_validators.py:278\u001b[0m, in \u001b[0;36mpydantic.class_validators._generic_validator_cls.lambda2\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Tresors/Documents/Mandats/RocketScience/MPM/pulsar-metrics/pulsar_metrics/metrics/base.py:40\u001b[0m, in \u001b[0;36mMetricResults.timestamp_later_than_period_end\u001b[0;34m(cls, v, values, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@validator\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39meval_timestamp\u001b[39m\u001b[39m\"\u001b[39m, always\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtimestamp_later_than_period_end\u001b[39m(\u001b[39mcls\u001b[39m, v, values, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m v \u001b[39m<\u001b[39m values[\u001b[39m\"\u001b[39;49m\u001b[39mperiod_end\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[1;32m     41\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCurrent timestamp earlier than period end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m v\n",
      "\u001b[0;31mKeyError\u001b[0m: 'period_end'"
     ]
    }
   ],
   "source": [
    "MetricResults(\n",
    "                metric_name=driftTest._name,\n",
    "                type='drift',\n",
    "                model_id=driftTest._model_id,\n",
    "                model_version=driftTest._model_version,\n",
    "                feature=driftTest._feature_name,\n",
    "                value=0,\n",
    "                conf_int=None,\n",
    "                status=0,\n",
    "                threshold=0,\n",
    "                period_start=driftTest._period_start,\n",
    "                period_end=driftTest._period_end,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>type</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_version</th>\n",
       "      <th>data_id</th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>status</th>\n",
       "      <th>threshold</th>\n",
       "      <th>period_start</th>\n",
       "      <th>period_end</th>\n",
       "      <th>eval_timestamp</th>\n",
       "      <th>conf_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.25, 0.8333333333333334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.25, 0.8333333333333334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.25, 0.8333333333333334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.25, 0.8333333333333334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brier</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.16666666666666666, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mse</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.16666666666666666, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mae</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.16666666666666666, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mape</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[0.16666666666666666, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r2</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>prediction</td>\n",
       "      <td>-4.454545</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-09-07 13:20:00.953935</td>\n",
       "      <td>[-7.209090909090912, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric_name         type model_id model_version data_id     feature  \\\n",
       "0   precision  performance        1             1    None  prediction   \n",
       "1    accuracy  performance        1             1    None  prediction   \n",
       "2      recall  performance        1             1    None  prediction   \n",
       "3          f1  performance        1             1    None  prediction   \n",
       "4       brier  performance        1             1    None  prediction   \n",
       "5         mse  performance        1             1    None  prediction   \n",
       "6         mae  performance        1             1    None  prediction   \n",
       "7        mape  performance        1             1    None  prediction   \n",
       "8          r2  performance        1             1    None  prediction   \n",
       "\n",
       "      value  status  threshold period_start period_end  \\\n",
       "0  0.583333   False        0.5   2022-07-01 2022-07-01   \n",
       "1  0.583333   False        0.5   2022-07-01 2022-07-01   \n",
       "2  0.583333   False        0.5   2022-07-01 2022-07-01   \n",
       "3  0.583333   False        0.5   2022-07-01 2022-07-01   \n",
       "4  0.416667    True        0.5   2022-07-01 2022-07-01   \n",
       "5  0.416667    True        0.5   2022-07-01 2022-07-01   \n",
       "6  0.416667    True        0.5   2022-07-01 2022-07-01   \n",
       "7  0.416667    True        0.5   2022-07-01 2022-07-01   \n",
       "8 -4.454545    True        0.5   2022-07-01 2022-07-01   \n",
       "\n",
       "              eval_timestamp                     conf_int  \n",
       "0 2022-09-07 13:20:00.953935   [0.25, 0.8333333333333334]  \n",
       "1 2022-09-07 13:20:00.953935   [0.25, 0.8333333333333334]  \n",
       "2 2022-09-07 13:20:00.953935   [0.25, 0.8333333333333334]  \n",
       "3 2022-09-07 13:20:00.953935   [0.25, 0.8333333333333334]  \n",
       "4 2022-09-07 13:20:00.953935  [0.16666666666666666, 0.75]  \n",
       "5 2022-09-07 13:20:00.953935  [0.16666666666666666, 0.75]  \n",
       "6 2022-09-07 13:20:00.953935  [0.16666666666666666, 0.75]  \n",
       "7 2022-09-07 13:20:00.953935  [0.16666666666666666, 0.75]  \n",
       "8 2022-09-07 13:20:00.953935    [-7.209090909090912, 0.0]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e1672c1cddd760a5eef9058cedf44072c5597a6d9e66edb5761fc3a4dde1295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
